{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accounting for Spatial Autocorrelation in Regression Models\n",
    "\n",
    "Tobler's First Law of Geography says *\"Everything is related to everything else.  But near things are more related than distant things.\"*  \n",
    "\n",
    "An important assumption when performing traditional regressions is that observations are independent.  The fact that observation A is high does not affect the probability that observation B is also high.  \n",
    "\n",
    "Tobler's First Law means that for spatial datasets, that assumption basically never holds.  If observation A is close to observation B, they will likely have similar values (i.e. they are **spatially autocorrelated**).  If our observations are no longer independent, we can't rely on the results of an ordinary regression.\n",
    "\n",
    "This notebook provides you with some tools to account for spatial autocorrelation, specifically a **spatial lag model** and a **spatial error model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Learning concepts with a toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the necessary libraries\n",
    "\n",
    "When you run the cell below, you may get a warning regarding the specific version of R the libraries were built under.  You can ignore this warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(spdep)\n",
    "library(spatialreg)\n",
    "library(GISTools)\n",
    "library(rgdal)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the data\n",
    "\n",
    "Spatial datasets that you want to use in R are most conveniently stored in a data format called a **shapefile** (which is actually a collection of several files).\n",
    "\n",
    "To be able to use them in R, however, you will need to load them into a **spatial data frame**.  The code below will load the file and print out a summary of a toy dataset designed to illustrate the problems of spatial autocorrelation.\n",
    "\n",
    "The important fields in this data set are CRIME, which is a measure of the crime rate in each region, and MINPOP, which is a measure of the population of color in each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf <-readOGR(\"data/examples.shp\")\n",
    "summary(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualize the data\n",
    "\n",
    "tmap is a good library to visualize spatial data in R, but sometimes it doesn't work.  Below is a function that will create a choropleth map from a spatial data frame using the GISTools library instead.  \n",
    "\n",
    "You can read more about creating these types of maps in GISTools at https://www.rdocumentation.org/packages/GISTools/versions/0.7-4/topics/choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth_map <- function(dataframe, var,title,classes,cutter=sdCuts, ramp=\"RdPu\") {\n",
    "    variable <- as.numeric(var)\n",
    "    variable.shade <- auto.shading(variable,cutter=cutter,n=classes,cols=brewer.pal(classes,ramp))\n",
    "    choropleth(dataframe,variable,shading=variable.shade)\n",
    "    title(title, cex.main=2)  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to visualize the variables, we need to pass correct parameters to the function we defined above.  Let's start with the MINPOP variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = sdf # which dataframe to use\n",
    "var = sdf$MINPOP # which variable will be mapped\n",
    "title = \"Population of People of Color\" # the title to print at the top of the figure\n",
    "classes = 5 # the number of groups to break the data into\n",
    "ramp = \"RdPu\" # the color ramp to use.  Since values go from high to low, a ramp that goes from light to dark is appropriate\n",
    "\n",
    "choropleth_map (dataframe,var,title, classes, ramp=ramp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can map the CRIME variable.  **Try to create the code yourself in the cell below, using the examples above.  If you have trouble, [check here](https://github.com/travisormsby/day_of_data/blob/master/crime_map_answer.txt) for the answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a non-spatial regression model\n",
    "\n",
    "Visually, we can see that the two variables have quite a bit of overlap, which makes us think they might be correlated.  The code below will create an ordinary least squares (OLS) regression model with MINPOP as the explanatory variable and CRIME as the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the regression model\n",
    "ols <- lm(CRIME ~ MINPOP, data = sdf)\n",
    "\n",
    "#print the summary\n",
    "summary(ols)\n",
    "\n",
    "#plot the relationship\n",
    "plot(sdf$MINPOP, sdf$CRIME)\n",
    "abline(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, how would you interpret the relationship between these two variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Think spatially\n",
    "\n",
    "Just looking at the results above, you might rush to publish your analysis without thinking about the effects of spatial autocorrelation.\n",
    "\n",
    "But since you were smart enough to attend this session, you know better than that.  \n",
    "\n",
    "What if we mapped the residuals from the OLS model?  If the model was appropriate, then you wouldn't be able to use a region's location to predict the value of the residual (i.e. the residuals would be spatially random).\n",
    "\n",
    "The code below will use our mapping function to map the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the ols model residuals\n",
    "dataframe = sdf\n",
    "var = resid(ols)\n",
    "title = \"OLS Model Residuals\"\n",
    "classes = 5\n",
    "ramp = \"RdBu\" # since residuals are both positive and negative, a diverging color ramp like Red-Blue is appropriate\n",
    "\n",
    "\n",
    "choropleth_map (dataframe,var,title, classes, ramp=ramp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that look spatially random to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't always have such obvious datasets, and we need a way to test the degree of spatial autocorrelation.  **Moran's I** is a statistic that measures spatial autocorrelation.  Its value can range from -1 to 1.  A value of 0 indicates no autocorrelation.  A positive value indicates that Tobler's law holds true: close things are more similar than distant things.  A negative value indicates the opposite: close things are more dissimilar than distant things (this is pretty rare in real life).\n",
    "\n",
    "To calculate Moran's I, the first thing we need to do is figure out what it means for things to be \"close\".  We'll use the definition that two regions are \"close\" if they share an edge and \"far\" if they don't.\n",
    "\n",
    "The code below will convert the region polygons into a contiguity graph where each region is a node and each edge connects a region to the other regions it shares an edge with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a contiguity graph\n",
    "sdf.nb <- poly2nb(sdf)\n",
    "\n",
    "# visualize the contiguity graph\n",
    "plot(sdf.nb, coordinates(sdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use that contiguity graph to create what's called a row-standardized spatial weights matrix.  This matrix is needed to calculate Moran's I.\n",
    "\n",
    "We're not going to go into all the math behind what this matrix is, but you can read more about it here: https://geodacenter.github.io/workbook/4a_contig_weights/lab4a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a row-standardized neighborhood weights matrix W\n",
    "W <- nb2listw(sdf.nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the weights matrix, we can measure the autocorrelation in the residuals.  Given the map we saw above, we should expect this number to be positive and closer to 1 than 0.\n",
    "\n",
    "The code below will calculate Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the residuals as a field to the spatial data frame\n",
    "sdf$ols.res <- resid(ols) \n",
    "\n",
    "# calculate Moran's I of the residuals, using the spatial weights matrix W\n",
    "moran.test(sdf$ols.res,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Correct for autocorrelation\n",
    "\n",
    "The high and statistically significant Moran's I value confirms what we saw in the map of the residuals: they are spatially autocorrelated and therefore the non-spatial OLS model doesn't tell us the right story about the relationship between the variables.  But Moran's I doesn't tell us what we should do about it.\n",
    "\n",
    "Primarily, we need to decide whether to use a spatial lag model or a spatial error model to create a better specified model.  \n",
    "\n",
    "A **spatial lag model** treats the spatial autocorrelation as the result of some kind of diffusion in your response variable.  Pollution is a good example of autocorrelation due to spatial lag.  Areas close to a pollution source have higher pollution values because the pollution spread to them from the source.\n",
    "\n",
    "A **spatial error model** treats the spatial autocorrelation as the result of some autocorrelated variable that isn't being accounted for in the model.  Maybe you don't know what it is, or maybe you can't measure it, but for whatever reason, you can't account for it in the model.  The spatial error model can control for this missing variable.\n",
    "\n",
    "Ideally, your choice of a spatial lag or spatial error model should be driven by your subject matter expertise and understanding of the underlying phenomenon.  If spatial autocorrelation in your response variable can plausibly be said to be due to diffusion, you should use a lag model.  Use an error model otherwise.\n",
    "\n",
    "But sometimes you don't really know.  Fortunately, we can turn to a statistical test called the Lagrage Multiplier to help us pick.  The code below will run the test on the OLS model we created earlier and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM <- lm.LMtests(ols, W, test=\"all\")\n",
    "summary(LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yeah, that's a lot of numbers.  What do they mean?\n",
    "\n",
    "First we're looking at the **LMerr** and **LMlag** values.  If the LMerr value is a lot higher, than a spatial error model will probably create a better model fit.  If the LMlag value is a lot higher, than a spatial lag model will probably be better.\n",
    "\n",
    "Lots of times, however, you get the same thing as this dataset: both values are pretty close together.  There is a \"robust\" version of each test that is intended to help.  Compare the **RLMerr** value to the **RLMlag** value.  Whichever one is higher and statistically significant will create a better model fit.  If the robust values are also similar, probably both spatial lag and spatial error are having an effect, and there is no good way to account for both of them at once.  In this case, however, the robust test suggests that a spatial lag model is more appropriate than spatial error.  \n",
    "\n",
    "Again, this is a good time to remind you that using the Lagrange Multiplier test is a second-best option.  It won't be good as actually understanding the phenomenon.\n",
    "\n",
    "The code below will create a spatial lag model using the spatial weights matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag <- lagsarlm(CRIME ~ MINPOP, data = sdf, W)\n",
    "summary(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four important values to pay attention to in the output:\n",
    "\n",
    "* **variable estimate** - this indicates whether the relationship is positively or negatively correlated\n",
    "* **Pr(>|z|)** - this indicates the probability that the relationship is real (as opposed to due to random chance)\n",
    "* **AIC** - this is a measure of the spatial model fit.  For our purposes, you can compare AIC for models that have the same response variable values.  Lower AIC indicates better fit, as long as the difference is more than about 2 or 3.\n",
    "* **AIC** for lm - this is a measure of the non-spatial model fit.\n",
    "\n",
    "In this case, we find that the relationship in the spatial regression model is still positive, just like it was in the OLS model.  The probability that this relationship is due to random chance, however, is much higher than it was in the OLS model.  This value is now to high to plausibly reject the idea that crime rates are uncorrelated with populations of color.\n",
    "\n",
    "Comparing AIC values for the two models, we find that the spatial lag model is a much better fit than the non-spatial OLS model.\n",
    "\n",
    "To convince ourselves that we have improved the model, try mapping the residuals from the lag model and calculating Moran's I.  If it really worked, the residuals should look more randomly distributed and Moran's I should be a lot closer to 0.\n",
    "\n",
    "**Try to create the code yourself in the cell below, using the examples above.  If you have trouble, [check here](https://github.com/travisormsby/day_of_data/blob/master/lag_model_answers.txt) for the answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create a Spatial Error Model just for fun\n",
    "\n",
    "Since a lag model won't always be best, you're going to want to know how to actually create spatial error models.  The code below will create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem <- errorsarlm(CRIME~MINPOP,data = sdf, W)\n",
    "summary(sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in the same values as we got from the spatial lag model output.  Some differences you should notice is that the sign on the correlation coefficient is now negative, but is even more likely to be due to chance.  The AIC is lower than the non-spatial model, but higher than the spatial lag model, which is further confirmation that the lag model provides the better fit.\n",
    "\n",
    "Mapping and calculating Moran's I for the residuals is left to the interested reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: So What?\n",
    "\n",
    "The OLS model is simply wrong.  And if we hadn't bee thinking spatially, we might have published those wrong results.  The potential harm from publishing bad research extends far beyond whatever embarrasment we might feel from having somebody else prove us wrong later.  That publication could have had serious consequences for policing, legislation, and society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Correct for spatial autocorrelation in a real dataset\n",
    "\n",
    "A toy dataset like we used above is fine for demonstrating a concept.  But we want to apply these techniques to a real dataset.\n",
    "\n",
    "### Beginner:\n",
    "\n",
    "Run through the steps below\n",
    "\n",
    "### Intermediate:\n",
    "\n",
    "Run through the steps below a few times, testing different linear models each time\n",
    "\n",
    "### Expert:\n",
    "\n",
    "Run through the steps below using your own spatial data.  You may need to load them into a spatial dataframe differently if they are not already in shapefile format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.sdf <- readOGR(\"data/censustract.shp\")\n",
    "summary(ct.sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map of NO2 Exposure\n",
    "dataframe = ct.sdf\n",
    "var = ct.sdf$Avg_Avg_NO\n",
    "title = \"NO2 Exposure\"\n",
    "classes = 5\n",
    "ramp = \"RdPu\"\n",
    "\n",
    "choropleth_map(dataframe,var,title, classes, ramp=ramp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map of any other variable in the dataset\n",
    "dataframe = ct.sdf\n",
    "var = \n",
    "title = \n",
    "classes =\n",
    "ramp =\n",
    "\n",
    "choropleth_map(dataframe,var,title, classes, ramp=ramp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a Non-spatial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the regression model.  \n",
    "\n",
    "\n",
    "# print the summary\n",
    "\n",
    "\n",
    "# plot the relationship\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Think Spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the residuals\n",
    "\n",
    "\n",
    "# create a contiguity graph\n",
    "\n",
    "\n",
    "# visualize the contiguity graph\n",
    "\n",
    "\n",
    "# create a row-standardized neighborhood weights matrix W\n",
    "\n",
    "\n",
    "# add the residuals from the OLS model as a field to the spatial data frame\n",
    " \n",
    "\n",
    "# calculate Moran's I of the OLS residuals, using the spatial weights matrix W\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did your non-spatial model do?  Do you need to correct for spatial autocorrelation?  \n",
    "\n",
    "If not, you're done - go back and see if you can find a linear model that does need correction.\n",
    "\n",
    "If you do need to correct for autocorrelation, keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Correct for spatial autocorrelation\n",
    "\n",
    "Are you enough of a subject matter expert on these data to make an argument about whether a spatial lag model or a spatial error model is more appropriate?  If so, skip the Lagrange Multiplier test.  If not, run the test to see which one will provide a better model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your spatial lag or spatial error model in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What, if anything, changed between the OLS and the spatial regression model?  Did the AIC of the spatial model indicate improved model fit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
